{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='/home/myp7435/monkey_hrnet/hrnet/experiments/coco/hrnet/w32_384x288_adam_lr1e-3.yaml', dataDir='', logDir='', modelDir='', opts=[], prevModelDir='')\n",
      "AUTO_RESUME: False\n",
      "CUDNN:\n",
      "  BENCHMARK: True\n",
      "  DETERMINISTIC: False\n",
      "  ENABLED: True\n",
      "DATASET:\n",
      "  COLOR_RGB: True\n",
      "  DATASET: coco\n",
      "  DATA_FORMAT: jpg\n",
      "  FLIP: False\n",
      "  HYBRID_JOINTS_TYPE: \n",
      "  NUM_JOINTS_HALF_BODY: 8\n",
      "  PROB_HALF_BODY: 0.3\n",
      "  ROOT: /home/myp7435/monkey_hrnet/hrnet/data/coco/\n",
      "  ROT_FACTOR: 45\n",
      "  SCALE_FACTOR: 0.35\n",
      "  SELECT_DATA: False\n",
      "  TEST_SET: val2017\n",
      "  TRAIN_SET: train2017\n",
      "DATA_DIR: \n",
      "DEBUG:\n",
      "  DEBUG: True\n",
      "  SAVE_BATCH_IMAGES_GT: True\n",
      "  SAVE_BATCH_IMAGES_PRED: True\n",
      "  SAVE_HEATMAPS_GT: True\n",
      "  SAVE_HEATMAPS_PRED: True\n",
      "GPUS: (0, 1)\n",
      "LOG_DIR: /home/myp7435/monkey_hrnet/log/\n",
      "LOSS:\n",
      "  TOPK: 8\n",
      "  USE_DIFFERENT_JOINTS_WEIGHT: False\n",
      "  USE_OHKM: False\n",
      "  USE_TARGET_WEIGHT: True\n",
      "MODEL:\n",
      "  EXTRA:\n",
      "    FINAL_CONV_KERNEL: 1\n",
      "    PRETRAINED_LAYERS: ['conv1', 'bn1', 'conv2', 'bn2', 'layer1', 'transition1', 'stage2', 'transition2', 'stage3', 'transition3', 'stage4']\n",
      "    STAGE2:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4]\n",
      "      NUM_BRANCHES: 2\n",
      "      NUM_CHANNELS: [32, 64]\n",
      "      NUM_MODULES: 1\n",
      "    STAGE3:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4, 4]\n",
      "      NUM_BRANCHES: 3\n",
      "      NUM_CHANNELS: [32, 64, 128]\n",
      "      NUM_MODULES: 4\n",
      "    STAGE4:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4, 4, 4]\n",
      "      NUM_BRANCHES: 4\n",
      "      NUM_CHANNELS: [32, 64, 128, 256]\n",
      "      NUM_MODULES: 3\n",
      "  HEATMAP_SIZE: [512, 384]\n",
      "  IMAGE_SIZE: [512, 384]\n",
      "  INIT_WEIGHTS: True\n",
      "  NAME: pose_hrnet\n",
      "  NUM_JOINTS: 21\n",
      "  PRETRAINED: /home/myp7435/monkey_hrnet/hrnet/output/coco/pose_hrnet/w32_384x288_adam_lr1e-3/model_best.pth\n",
      "  SIGMA: 3\n",
      "  TAG_PER_JOINT: True\n",
      "  TARGET_TYPE: gaussian\n",
      "OUTPUT_DIR: /home/myp7435/monkey_hrnet/output/\n",
      "PIN_MEMORY: True\n",
      "PRINT_FREQ: 100\n",
      "RANK: 0\n",
      "TEST:\n",
      "  BATCH_SIZE_PER_GPU: 8\n",
      "  BBOX_THRE: 1.0\n",
      "  COCO_BBOX_FILE: data/coco/person_detection_results/COCO_val2017_detections_AP_H_56_person.json\n",
      "  FLIP_TEST: False\n",
      "  IMAGE_THRE: 0.0\n",
      "  IN_VIS_THRE: 0.2\n",
      "  MODEL_FILE: \n",
      "  NMS_THRE: 1.0\n",
      "  OKS_THRE: 0.9\n",
      "  POST_PROCESS: True\n",
      "  SHIFT_HEATMAP: True\n",
      "  SOFT_NMS: False\n",
      "  USE_GT_BBOX: True\n",
      "TRAIN:\n",
      "  BATCH_SIZE_PER_GPU: 8\n",
      "  BEGIN_EPOCH: 0\n",
      "  CHECKPOINT: \n",
      "  END_EPOCH: 20\n",
      "  GAMMA1: 0.99\n",
      "  GAMMA2: 0.0\n",
      "  LR: 0.001\n",
      "  LR_FACTOR: 0.1\n",
      "  LR_STEP: [8, 16]\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  OPTIMIZER: adam\n",
      "  RESUME: False\n",
      "  SHUFFLE: True\n",
      "  WD: 0.0001\n",
      "WORKERS: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating /home/myp7435/monkey_hrnet/output/coco/pose_hrnet/w32_384x288_adam_lr1e-3\n",
      "=> creating /home/myp7435/monkey_hrnet/log/coco/pose_hrnet/w32_384x288_adam_lr1e-3_2021-06-23-07-57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> loading model from /home/myp7435/monkey_hrnet/output/coco/pose_hrnet/w32_384x288_adam_lr1e-3/model_best.pth\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# import _init_paths\n",
    "import sys\n",
    "sys.path.append('../monkey_hrnet/hrnet/lib/')\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.loss import JointsMSELoss\n",
    "from utils.utils import get_optimizer\n",
    "from utils.utils import save_checkpoint\n",
    "from utils.utils import create_logger\n",
    "from utils.utils import get_model_summary\n",
    "\n",
    "from function import train\n",
    "from function import validate\n",
    "\n",
    "# import dataset\n",
    "import models\n",
    "# torch.set_default_dtype(torch.float16)\n",
    "parser = argparse.ArgumentParser(description='Train keypoints network')\n",
    "# general\n",
    "parser.add_argument('--cfg',\n",
    "                    help='experiment configure file name',\n",
    "                    required=True,\n",
    "                    type=str)\n",
    "\n",
    "parser.add_argument('opts',\n",
    "                    help=\"Modify config options using the command-line\",\n",
    "                    default=None,\n",
    "                    nargs=argparse.REMAINDER)\n",
    "\n",
    "# philly\n",
    "parser.add_argument('--modelDir',\n",
    "                    help='model directory',\n",
    "                    type=str,\n",
    "                    default='')\n",
    "parser.add_argument('--logDir',\n",
    "                    help='log directory',\n",
    "                    type=str,\n",
    "                    default='')\n",
    "parser.add_argument('--dataDir',\n",
    "                    help='data directory',\n",
    "                    type=str,\n",
    "                    default='')\n",
    "parser.add_argument('--prevModelDir',\n",
    "                    help='prev Model directory',\n",
    "                    type=str,\n",
    "                    default='')\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(['--cfg', '/home/myp7435/monkey_hrnet/hrnet/experiments/coco/hrnet/w32_384x288_adam_lr1e-3.yaml'])\n",
    "#                          '--modelDir', '/home/myp7435/monkey_hrnet/hrnet/output/coco/pose_hrnet/w32_384x288_adam_lr1e-3/model_best.pth'])\n",
    "# args = parser.parse_args(['--modelDir', '/home/myp7435/monkey_hrnet/hrnet/output/coco/pose_hrnet/w32_384x288_adam_lr1e-3/model_best.pth'])\n",
    "\n",
    "update_config(cfg, args)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'train')\n",
    "\n",
    "logger.info(pprint.pformat(args))\n",
    "logger.info(cfg)\n",
    "\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "\n",
    "# model = eval('models.'+cfg.MODEL.NAME+'.get_pose_net')(cfg, is_train=True).half()\n",
    "model = eval('models.'+cfg.MODEL.NAME+'.get_pose_net')(cfg, is_train=False)\n",
    "model_state_file = os.path.join(\n",
    "            final_output_dir, 'model_best.pth'\n",
    "        )\n",
    "logger.info('=> loading model from {}'.format(model_state_file))\n",
    "model.load_state_dict(torch.load(model_state_file))\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=cfg.GPUS).cuda()\n",
    "\n",
    "criterion = JointsMSELoss(\n",
    "    use_target_weight=cfg.LOSS.USE_TARGET_WEIGHT\n",
    ").cuda()\n",
    "\n",
    "# Data loading code\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy model file\n",
    "try:\n",
    "#     this_dir = os.path.dirname(__file__)\n",
    "    this_dir = os.getcwd()\n",
    "except NameError:  # We are the main py2exe script, not a module\n",
    "    import sys\n",
    "    this_dir = os.path.abspath(sys.argv[0])\n",
    "\n",
    "shutil.copy2(\n",
    "    os.path.join(this_dir, 'hrnet/lib/models', cfg.MODEL.NAME + '.py'),\n",
    "    final_output_dir)\n",
    "# logger.info(pprint.pformat(model))\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(log_dir=tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "\n",
    "\n",
    "best_perf = 0.0\n",
    "best_model = False\n",
    "last_epoch = -1\n",
    "optimizer = get_optimizer(cfg, model)\n",
    "begin_epoch = cfg.TRAIN.BEGIN_EPOCH\n",
    "checkpoint_file = os.path.join(\n",
    "    final_output_dir, 'checkpoint.pth'\n",
    ")\n",
    "\n",
    "if cfg.AUTO_RESUME and os.path.exists(checkpoint_file):\n",
    "    logger.info(\"=> loading checkpoint '{}'\".format(checkpoint_file))\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_perf = checkpoint['perf']\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    logger.info(\"=> loaded checkpoint '{}' (epoch {})\".format(\n",
    "        checkpoint_file, checkpoint['epoch']))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, cfg.TRAIN.LR_STEP, cfg.TRAIN.LR_FACTOR,\n",
    "    last_epoch=last_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from my_utils import read_dlc_labeled_data\n",
    "root_dir = '/home/myp7435/downsampled_data'\n",
    "folders = ['cam_0', 'cam_1', 'cam_2', 'cam_3', \n",
    "                 'cam_0_0610', 'cam_1_0610', 'cam_2_0610', 'cam_3_0610', \n",
    "                 'cam_0_0811', 'cam_1_0811', 'cam_2_0811', 'cam_3_0811',\n",
    "                 'cam_0_0811_b5', 'cam_1_0811_b5', 'cam_2_0811_b5', 'cam_3_0811_b5',\n",
    "                 'cam_0_0811_b6', 'cam_1_0811_b6', 'cam_2_0811_b6', 'cam_3_0811_b6',\n",
    "                 'cam_0_0827_b1', 'cam_1_0827_b1', 'cam_2_0827_b1', 'cam_3_0827_b1', \n",
    "                 'cam_0_0827_b2', 'cam_1_0827_b2', 'cam_2_0827_b2', 'cam_3_0827_b2', \n",
    "                 'cam_0_1103_b1', 'cam_1_1103_b1', 'cam_2_1103_b1', 'cam_3_1103_b1', \n",
    "                 'cam_0_1103_b2', 'cam_1_1103_b2', 'cam_2_1103_b2', 'cam_3_1103_b2', \n",
    "                ]\n",
    "df = read_dlc_labeled_data(root_dir, folders)\n",
    "#%%\n",
    "from CustomDataset import CustomDataset\n",
    "\n",
    "import numpy as np\n",
    "idx = np.random.choice(len(df), int(len(df)*0.9), replace=False)\n",
    "df_train = [df[i] for i in idx]\n",
    "df_valid = [df[i] for i in np.arange(len(df)) if i not in idx]\n",
    "\n",
    "train_dataset = CustomDataset(cfg, df_train, \n",
    "                              transform=transforms.Compose([transforms.ToTensor(),normalize,]))\n",
    "\n",
    "valid_dataset = CustomDataset(cfg, df_valid, \n",
    "                              transform=transforms.Compose([transforms.ToTensor(),normalize,]))\n",
    "\n",
    "#%%\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.TRAIN.BATCH_SIZE_PER_GPU*len(cfg.GPUS),\n",
    "    shuffle=cfg.TRAIN.SHUFFLE,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=cfg.PIN_MEMORY\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU*len(cfg.GPUS),\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=cfg.PIN_MEMORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "\n",
      "Epoch: [0][0/942]\tTime 8.458s (8.458s)\tSpeed 1.9 samples/s\tData 0.667s (0.667s)\tLoss 0.00002 (0.00002)\tAccuracy 8.270 (8.270)\n",
      "Epoch: [0][100/942]\tTime 2.606s (2.684s)\tSpeed 6.1 samples/s\tData 0.445s (0.494s)\tLoss 0.00002 (0.00002)\tAccuracy 13.366 (9.685)\n",
      "Epoch: [0][200/942]\tTime 2.664s (2.672s)\tSpeed 6.0 samples/s\tData 0.437s (0.489s)\tLoss 0.00002 (0.00002)\tAccuracy 7.802 (10.005)\n",
      "Epoch: [0][300/942]\tTime 2.592s (2.669s)\tSpeed 6.2 samples/s\tData 0.436s (0.488s)\tLoss 0.00002 (0.00002)\tAccuracy 12.878 (10.181)\n",
      "Epoch: [0][400/942]\tTime 2.605s (2.668s)\tSpeed 6.1 samples/s\tData 0.435s (0.488s)\tLoss 0.00002 (0.00002)\tAccuracy 13.095 (10.216)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(begin_epoch, cfg.TRAIN.END_EPOCH):\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # train for one epoch\n",
    "    train(cfg, train_loader, model, criterion, optimizer, epoch,\n",
    "          final_output_dir, tb_log_dir, writer_dict)\n",
    "    best_model = True\n",
    "\n",
    "#     evaluate on validation set\n",
    "    perf_indicator = validate(\n",
    "       cfg, valid_loader, valid_dataset, model, criterion,\n",
    "       final_output_dir, tb_log_dir, writer_dict\n",
    "   )\n",
    "\n",
    "    if perf_indicator >= best_perf:\n",
    "        best_perf = perf_indicator\n",
    "        best_model = True\n",
    "    else:\n",
    "        best_model = False\n",
    "    if perf_indicator <= best_perf:\n",
    "        best_perf = perf_indicator\n",
    "        best_model = True\n",
    "    else:\n",
    "        best_model = False\n",
    "\n",
    "    logger.info('=> saving checkpoint to {}'.format(final_output_dir))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'model': cfg.MODEL.NAME,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_state_dict': model.module.state_dict(),\n",
    "        'perf': perf_indicator,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, best_model, final_output_dir)\n",
    "\n",
    "final_model_state_file = os.path.join(\n",
    "    final_output_dir, 'final_state.pth'\n",
    ")\n",
    "logger.info('=> saving final model state to {}'.format(\n",
    "    final_model_state_file)\n",
    ")\n",
    "torch.save(model.module.state_dict(), final_model_state_file)\n",
    "writer_dict['writer'].close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 7/3300 [00:00<00:53, 61.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/experiment/cam_0_trimmed.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/experiment/cam_0_trimmed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/experiment/cam_0_trimmed.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 6/1800 [00:00<00:33, 53.38it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/calib/cam_0.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/calib/cam_0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/calib/cam_0.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 6/3300 [00:00<00:58, 56.51it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/experiment/cam_1_trimmed.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/experiment/cam_1_trimmed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/experiment/cam_1_trimmed.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 7/1800 [00:00<00:29, 59.95it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/calib/cam_1.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/calib/cam_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/calib/cam_1.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 7/3300 [00:00<00:58, 56.49it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/experiment/cam_2_trimmed.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/experiment/cam_2_trimmed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/experiment/cam_2_trimmed.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 8/1800 [00:00<00:24, 73.42it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/calib/cam_2.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/calib/cam_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/calib/cam_2.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 8/3300 [00:00<00:45, 72.72it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/experiment/cam_3_trimmed.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/experiment/cam_3_trimmed.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/experiment/cam_3_trimmed.mp4\n",
      "(512.0, 384.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 8/1800 [00:00<00:24, 72.05it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/myp7435/downsampled_videos/1217/calib/cam_3.mp4.\n",
      "Moviepy - Writing video /home/myp7435/downsampled_videos/1217/calib/cam_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/myp7435/downsampled_videos/1217/calib/cam_3.mp4\n",
      "(512.0, 384.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from my_utils import generate_downsampled_video\n",
    "\n",
    "date = '1217'\n",
    "save_directory = os.path.join('/home/myp7435/downsampled_videos', date)\n",
    "if not os.path.exists(save_directory):\n",
    "    os.mkdir(save_directory)\n",
    "    exp_save_dir = os.path.join(save_directory, 'experiment')\n",
    "    calib_save_dir = os.path.join(save_directory, 'calib')\n",
    "    os.mkdir(exp_save_dir)\n",
    "    os.mkdir(calib_save_dir)\n",
    "\n",
    "videos1 = ['cam_0_trimmed.mp4', 'cam_1_trimmed.mp4', 'cam_2_trimmed.mp4', 'cam_3_trimmed.mp4']\n",
    "videos2 = ['cam_0.avi', 'cam_1.avi', 'cam_2.avi', 'cam_3.avi']\n",
    "\n",
    "video_directory = os.path.join('/home/myp7435/Pop_freeReach_0317_merged-Min-2020-04-19/videos', date)\n",
    "calib_directory = '/home/myp7435/Pop_freeReach_0317_merged-Min-2020-04-19/videos/calib_' + date\n",
    "\n",
    "for vid1, vid2 in zip(videos1, videos2):\n",
    "    video_path = os.path.join(video_directory, vid1)\n",
    "    calib_path = os.path.join(calib_directory, vid2)\n",
    "    exp_save_path = os.path.join(exp_save_dir, vid1)\n",
    "    calib_save_path = os.path.join(calib_save_dir, vid2.split('.')[0] + '.mp4')\n",
    "    width = 512\n",
    "    generate_downsampled_video(video_path, exp_save_path, width)\n",
    "    generate_downsampled_video(calib_path, calib_save_path, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [05:25<00:00, 10.14it/s]\n",
      "100%|██████████| 3300/3300 [05:27<00:00, 10.07it/s]\n",
      "100%|██████████| 3300/3300 [05:27<00:00, 10.08it/s]\n",
      "100%|██████████| 3300/3300 [05:26<00:00, 10.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from my_utils import infer_video\n",
    "\n",
    "joints_name = ['Wrist', 'CMC_thumb', 'MCP_thumb', 'MCP1', 'MCP2', 'MCP3', 'MCP4',\n",
    "          'IP_thumb', 'PIP1', 'PIP2', 'PIP3', 'PIP4', 'Dip1', 'Dip2', 'Dip3', 'Dip4',\n",
    "          'Tip_thumb', 'Tip1', 'Tip2', 'Tip3', 'Tip4']\n",
    "for vid in videos1:\n",
    "    video_path = os.path.join(exp_save_dir, vid)\n",
    "    infer_video(video_path, model, joints_name, \n",
    "                transform=transforms.Compose([transforms.ToTensor(),normalize,]), downsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [01:17<00:00, 233.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from my_utils import create_labeled_video\n",
    "\n",
    "joints_name = ['Wrist', 'CMC_thumb', 'MCP_thumb', 'MCP1', 'MCP2', 'MCP3', 'MCP4',\n",
    "          'IP_thumb', 'PIP1', 'PIP2', 'PIP3', 'PIP4', 'Dip1', 'Dip2', 'Dip3', 'Dip4',\n",
    "          'Tip_thumb', 'Tip1', 'Tip2', 'Tip3', 'Tip4']\n",
    "\n",
    "for vid in videos1:\n",
    "    video_path = os.path.join(exp_save_dir, vid)\n",
    "    infer_video(video_path, model, joints_name, \n",
    "                transform=transforms.Compose([transforms.ToTensor(),normalize,]), downsample=1)\n",
    "create_labeled_video(video_path, csvpath, joints_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
