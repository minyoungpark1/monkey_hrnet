{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:46<00:00,  2.72it/s]\n",
      "100%|██████████| 126/126 [00:31<00:00,  4.04it/s]\n",
      "100%|██████████| 126/126 [00:33<00:00,  3.78it/s]\n",
      "100%|██████████| 126/126 [00:43<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "parent_folder = '/home/myp7435/downsampled_videos/1217'\n",
    "label_paths = [os.path.join(parent_folder, 'labeled', 'cam_'+str(i)+'_labeled.csv') for i in range(4)]\n",
    "# infer_paths = [os.path.join(parent_folder, 'experiment', 'cam_'+str(i)+'_trimmed_output.csv') for i in range(4)]\n",
    "# infer_paths = [os.path.join(parent_folder, 'experiment_sam', 'cam_'+str(i)+'_output.csv') for i in range(4)]\n",
    "infer_paths = [os.path.join(parent_folder, 'experiment_dlc', 'cam_'+str(i)+'_output.csv') for i in range(4)]\n",
    "\n",
    "\n",
    "joints = ['Wrist', 'CMC_thumb', 'MCP_thumb', 'MCP1', 'MCP2', 'MCP3', 'MCP4',\n",
    "          'IP_thumb', 'PIP1', 'PIP2', 'PIP3', 'PIP4', 'Dip1', 'Dip2', 'Dip3', 'Dip4',\n",
    "          'Tip_thumb', 'Tip1', 'Tip2', 'Tip3', 'Tip4']\n",
    "\n",
    "likelihood_cutoffs = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "err_likelihood_cut = {cutoff:[] for cutoff in likelihood_cutoffs}\n",
    "reject_likelihood_cut = {cutoff:0 for cutoff in likelihood_cutoffs}\n",
    "\n",
    "for label_path, infer_path in zip(label_paths, infer_paths):\n",
    "    df_label = pd.read_csv(label_path, header=[2,3], index_col=0)\n",
    "    df_infer = pd.read_csv(infer_path, header=[0,1], index_col=0)\n",
    "    \n",
    "    indices = [int(re.findall(r'\\d+', file)[-1]) for file in df_label.index]\n",
    "    \n",
    "    \n",
    "    for i, index in enumerate(tqdm(indices)):\n",
    "        for joint in joints:\n",
    "            for likelihood_cutoff in likelihood_cutoffs:\n",
    "                if df_infer[joint]['likelihood'][i] > likelihood_cutoff:\n",
    "                    label = np.array([df_label[joint]['x'][i], df_label[joint]['y'][i]])\n",
    "                    infer = np.array([df_infer[joint]['x'].iloc[index], df_infer[joint]['y'].iloc[index]])\n",
    "                    dist = np.linalg.norm(label - infer, axis=0)\n",
    "                    err_likelihood_cut[likelihood_cutoff].append(dist)\n",
    "                else:\n",
    "                    reject_likelihood_cut[likelihood_cutoff] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute test-error w/ different likelihood cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (0.05 cutoff): 17.36 ± 0.00621 (pixels) | 0.043 rejected\n",
      "Test error (0.1 cutoff): 17.22 ± 0.00639 (pixels) | 0.090 rejected\n",
      "Test error (0.15 cutoff): 17.35 ± 0.00692 (pixels) | 0.163 rejected\n",
      "Test error (0.2 cutoff): 17.53 ± 0.00740 (pixels) | 0.218 rejected\n",
      "Test error (0.25 cutoff): 17.54 ± 0.00779 (pixels) | 0.261 rejected\n",
      "Test error (0.3 cutoff): 17.45 ± 0.00804 (pixels) | 0.296 rejected\n",
      "Test error (0.35 cutoff): 17.56 ± 0.00846 (pixels) | 0.329 rejected\n",
      "Test error (0.4 cutoff): 17.63 ± 0.00886 (pixels) | 0.359 rejected\n",
      "Test error (0.45 cutoff): 17.82 ± 0.00952 (pixels) | 0.397 rejected\n",
      "Test error (0.5 cutoff): 17.79 ± 0.01018 (pixels) | 0.438 rejected\n"
     ]
    }
   ],
   "source": [
    "for likelihood_cutoff in likelihood_cutoffs:\n",
    "    prop_nan = reject_likelihood_cut[likelihood_cutoff]/(len(indices)*len(joints)*len(label_paths))\n",
    "    err_mean = np.nanmean(err_likelihood_cut[likelihood_cutoff])\n",
    "    err_stderr = np.nanstd(err_likelihood_cut[likelihood_cutoff])/np.sum(np.isfinite(err_likelihood_cut[likelihood_cutoff]))\n",
    "    print(f'Test error ({likelihood_cutoff} cutoff): {err_mean:.2f} ± {err_stderr:.5f} (pixels) | {prop_nan:.3f} rejected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute 3-D test-error for each keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrist : 8.95 ± 0.03097 (pixels) | 0.476 rejected\n",
      "CMC_thumb : 5.07 ± 0.02134 (pixels) | 0.222 rejected\n",
      "MCP_thumb : 5.60 ± 0.02691 (pixels) | 0.119 rejected\n",
      "MCP1 : 5.07 ± 0.02302 (pixels) | 0.008 rejected\n",
      "MCP2 : 5.10 ± 0.02041 (pixels) | 0.000 rejected\n",
      "MCP3 : 6.19 ± 0.02534 (pixels) | 0.024 rejected\n",
      "MCP4 : 6.99 ± 0.03158 (pixels) | 0.056 rejected\n",
      "IP_thumb : 6.46 ± 0.02974 (pixels) | 0.183 rejected\n",
      "PIP1 : 7.00 ± 0.03743 (pixels) | 0.040 rejected\n",
      "PIP2 : 8.81 ± 0.04020 (pixels) | 0.032 rejected\n",
      "PIP3 : 7.95 ± 0.03085 (pixels) | 0.127 rejected\n",
      "PIP4 : 9.05 ± 0.03784 (pixels) | 0.143 rejected\n",
      "Dip1 : 6.77 ± 0.03433 (pixels) | 0.294 rejected\n",
      "Dip2 : 12.50 ± 0.05090 (pixels) | 0.302 rejected\n",
      "Dip3 : 10.61 ± 0.03959 (pixels) | 0.175 rejected\n",
      "Dip4 : 8.85 ± 0.03735 (pixels) | 0.206 rejected\n",
      "Tip_thumb : 7.44 ± 0.02118 (pixels) | 0.913 rejected\n",
      "Tip1 : 10.93 ± 0.04876 (pixels) | 0.690 rejected\n",
      "Tip2 : 13.41 ± 0.05400 (pixels) | 0.603 rejected\n",
      "Tip3 : 10.01 ± 0.04842 (pixels) | 0.460 rejected\n",
      "Tip4 : 13.21 ± 0.05757 (pixels) | 0.746 rejected\n",
      "Total : 7.84 ± 0.00189 (pixels) | 0.277 rejected\n"
     ]
    }
   ],
   "source": [
    "# Load 3-D data\n",
    "labeled = pd.read_csv(os.path.join(parent_folder, 'labeled', \n",
    "                                    'output_3d_data_raw.csv'))\n",
    "infered = pd.read_csv(os.path.join(parent_folder, 'experiment_sam', \n",
    "                                    'output_3d_data_lpf.csv'))\n",
    "#                                     'output_3d_data_raw.csv'))\n",
    "    \n",
    "dists = []\n",
    "for j, joint in enumerate(joints):\n",
    "    \n",
    "    poi1_coord = np.stack([labeled[joint+'_x'], \n",
    "                           labeled[joint+'_y'], \n",
    "                           labeled[joint+'_z']], axis=1)\n",
    "    poi2_coord = np.stack([infered[joint+'_x'][indices], \n",
    "                           infered[joint+'_y'][indices], \n",
    "                           infered[joint+'_z'][indices]], axis=1)\n",
    "    dist = np.linalg.norm(poi1_coord - poi2_coord, axis=1)\n",
    "    err_mean = np.nanmean(dist)\n",
    "    err_stderr = np.nanstd(dist)/ len(dist)\n",
    "    prop_nan = np.sum(np.isnan(dist)) / len(dist)\n",
    "    dists.append(dist)\n",
    "    print(joint+f' : {err_mean:.2f} ± {err_stderr:.5f} (pixels) | {prop_nan:.3f} rejected')\n",
    "dists = np.array(dists).reshape(-1,)\n",
    "err_mean = np.nanmean(dists)\n",
    "err_stderr = np.nanstd(dists)/len(dists)\n",
    "prop_nan = np.sum(np.isnan(dists)) / len(dists)\n",
    "print(f'Total : {err_mean:.2f} ± {err_stderr:.5f} (pixels) | {prop_nan:.3f} rejected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpolate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/myp7435/downsampled_videos/1217/experiment/cam_0_logfile.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7560b86d0f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtimestamp_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimestamp_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtimestamp_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/myp7435/downsampled_videos/1217/experiment/cam_0_logfile.txt not found."
     ]
    }
   ],
   "source": [
    "timestamp_paths = [os.path.join(parent_folder, 'experiment', 'cam_'+str(i)+'_logfile.txt') for i in range(4)]\n",
    "max_timestamps = []\n",
    "timestamps = []\n",
    "for timestamp_path in timestamp_paths:\n",
    "    timestamp = np.loadtxt(timestamp_path)\n",
    "    timestamp_diff = np.round(timestamp[1] - timestamp[0])\n",
    "\n",
    "    if timestamp_diff > 4:\n",
    "        df = df.drop(0)\n",
    "        timestamp = timestamp[1:]\n",
    "\n",
    "    timestamp -= timestamp[0]\n",
    "    timestamps.append(timestamp*30)\n",
    "    max_timestamps.append(timestamp[-1]*30)\n",
    "    \n",
    "    max_timestamp = max(max_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 3-D test-error for each keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrist : 9.13 ± 0.05557 (mm) | 0.421 rejected\n",
      "CMC_thumb : 5.27 ± 0.02877 (mm) | 0.222 rejected\n",
      "MCP_thumb : 6.01 ± 0.03050 (mm) | 0.135 rejected\n",
      "MCP1 : 6.04 ± 0.03021 (mm) | 0.000 rejected\n",
      "MCP2 : 5.51 ± 0.02223 (mm) | 0.008 rejected\n",
      "MCP3 : 6.17 ± 0.02303 (mm) | 0.024 rejected\n",
      "MCP4 : 6.99 ± 0.02818 (mm) | 0.063 rejected\n",
      "IP_thumb : 5.98 ± 0.03245 (mm) | 0.230 rejected\n",
      "PIP1 : 7.47 ± 0.03667 (mm) | 0.071 rejected\n",
      "PIP2 : 8.69 ± 0.03879 (mm) | 0.095 rejected\n",
      "PIP3 : 8.78 ± 0.03525 (mm) | 0.127 rejected\n",
      "PIP4 : 9.21 ± 0.03993 (mm) | 0.127 rejected\n",
      "Dip1 : 8.48 ± 0.04899 (mm) | 0.214 rejected\n",
      "Dip2 : 9.91 ± 0.23380 (mm) | 0.865 rejected\n",
      "Dip3 : 11.44 ± 0.05116 (mm) | 0.167 rejected\n",
      "Dip4 : 9.94 ± 0.04915 (mm) | 0.262 rejected\n",
      "Tip_thumb : 8.40 ± 0.11301 (mm) | 0.810 rejected\n",
      "Tip1 : 11.82 ± 0.11843 (mm) | 0.667 rejected\n",
      "Tip2 : 12.30 ± 0.07327 (mm) | 0.333 rejected\n",
      "Tip3 : 11.52 ± 0.09897 (mm) | 0.532 rejected\n",
      "Tip4 : 13.30 ± 0.12197 (mm) | 0.690 rejected\n",
      "Total : 8.16 ± 4.70290 (mm) | 0.289 rejected\n"
     ]
    }
   ],
   "source": [
    "labeled = pd.read_csv(os.path.join(parent_folder, 'labeled', \n",
    "                                    'output_3d_data_raw.csv'))\n",
    "infered = pd.read_csv(os.path.join(parent_folder, 'experiment', \n",
    "                                    'output_3d_data_lpf_full.csv'))\n",
    "#                                     'output_3d_data_raw_full.csv'))\n",
    "    \n",
    "dists = []\n",
    "L = int(max_timestamp + 1)\n",
    "timestamp = timestamps[3]\n",
    "t = np.arange(0, L)/30\n",
    "\n",
    "for j, joint in enumerate(joints):\n",
    "    poi1_coord = np.stack([labeled[joint+'_x'], \n",
    "                           labeled[joint+'_y'], \n",
    "                           labeled[joint+'_z']], axis=1)\n",
    "    \n",
    "#     poi2_x = np.interp(timestamp[indices], t, infered[joint+'_x'])\n",
    "#     poi2_y = np.interp(timestamp[indices], t, infered[joint+'_y'])\n",
    "#     poi2_z = np.interp(timestamp[indices], t, infered[joint+'_z'])\n",
    "    \n",
    "    poi2_x = infered[joint+'_x'][np.round(timestamp[indices])]\n",
    "    poi2_y = infered[joint+'_y'][np.round(timestamp[indices])]\n",
    "    poi2_z = infered[joint+'_z'][np.round(timestamp[indices])]\n",
    "    \n",
    "    poi2_coord = np.stack([poi2_x, poi2_y, poi2_z], axis=1)\n",
    "    dist = np.linalg.norm(poi1_coord - poi2_coord, axis=1)\n",
    "    err_mean = np.nanmean(dist)\n",
    "    err_stderr = np.nanstd(dist)/np.sum(np.isfinite(dist))\n",
    "    prop_nan = np.sum(np.isnan(dist)) / len(dist)\n",
    "    dists.append(dist)\n",
    "    print(joint+f' : {err_mean:.2f} ± {err_stderr:.5f} (mm) | {prop_nan:.3f} rejected')\n",
    "dists = np.array(dists).reshape(-1,)\n",
    "err_mean = np.nanmean(dists)\n",
    "err_stderr = np.nanstd(dists)\n",
    "prop_nan = np.sum(np.isnan(dists)) / len(dists)\n",
    "print(f'Total : {err_mean:.2f} ± {err_stderr:.5f} (mm) | {prop_nan:.3f} rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
